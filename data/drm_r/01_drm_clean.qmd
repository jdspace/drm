---
title: "01_drm_clean"
author: "Jeremy Faulk"
format: html
editor: visual
---

## Setup

```{r setup, include=FALSE}
# 📦 Load helpful libraries
library(here)
library(readxl)
library(janitor)
library(tidyverse)
library(scales)
library(knitr)
library(purrr)

# 📌 Declare project root for 'here' (only needed once per session)
here::i_am("data/drm_r/01_drm_clean.qmd")
```

##📥 Load Combined DRM Dataset

```{r}
# 🔍 Define and read the combined DRM data file
path <- here("data", "drm_merged", "drm_qualtrics_quantitative.csv")
if (!file.exists(path)) stop("File not found: ", path)
# First row is column label
df <- read_csv(path)

# 👀 Preview structure
df %>%
  slice_head(n = 10)
```

##🧼 Clean and Standardize

```{r}
# 🗑️ Remove metadata/question label rows
df <- df[-c(2, 75, 81, 85, 90, 92, 95), ]

# 🧽 Standardize column names
df <- clean_names(df)

# 🚮 Remove junk rows that start with '{\"ImportId\":' in the SONA column
df <- df %>%
  filter(!str_detect(sona, "^\\{\"ImportId\":"))

# ✅ Confirm remaining rows
cat("Remaining rows after removing junk entries:", nrow(df), "\n")

# 🧼 Normalize SONA values (lowercase + trim whitespace)
df <- df %>%
  mutate(sona = str_trim(tolower(sona)))

# 🧾 SONA IDs to exclude (also lowercase to match)
drop_ids <- tolower(c(
  "Jps395@cornell.edu", "Njw75@cornell.edu", "92419", "87832", 
  "bjl99@cornell.edu", "74467", "Kl547@cornell.edu", "86920", 
  "km656@cornell.edu", "71665", "93025"
))

# 🚫 Filter out excluded participants
df <- df %>%
  filter(!(sona %in% drop_ids))

# ✅ Check result
cat("Remaining rows after exclusion:", nrow(df), "\n")

# 🧽 Remove duplicate suffixes (keep only .x columns if .y exists)
df <- df %>%
  select(-matches("\\.y$")) %>%  # Drop columns ending in .y
  rename_with(~ str_remove(., "\\.x$"), matches("\\.x$"))  # Remove .x from column names

# 🔁 Convert character-like columns to numeric, EXCLUDING `sona`
df <- df %>%
  mutate(across(
    .cols = intersect(names(select(., where(is.character))), names(df)[names(df) != "sona"]),
    .fns = ~ suppressWarnings(as.numeric(.))
  ))

# 🧾 Find duplicated SONA IDs
duplicated_ids <- df %>%
  filter(sona %in% sona[duplicated(sona) | duplicated(sona, fromLast = TRUE)])

# 💾 Save to output folder
write_csv(duplicated_ids, here("data", "drm_r", "outputs", "duplicated_ids.csv"))
```


## Identify Person-Level vs. Episode-Level Dataframes


```{r}
# 📋 Create a variable-level tagging template for manual review
variable_levels <- tibble(
  variable = names(df),
  level = ""  # Placeholder to manually enter 'person' or 'episode'
)

# 💾 Save to outputs folder for tagging
write_csv(variable_levels, here("data", "drm_r", "outputs", "variable_levels_template.csv"))

# 👁️ View in RStudio's Data window
View(variable_levels)

cat("✅ Variable-level tagging template saved to:\n",
    here("data", "drm_r", "outputs", "variable_levels_template.csv"), "\n")
```


## Identify Person-Level vs. Episode-Level Dataframes


```{text}
person_vars <- c("sona", "age", "gender", "baseline_wellbeing", ...)  # replace with actual vars
df_person <- df_merged %>% select(any_of(person_vars))

df_episode <- df_merged %>% select(-any_of(person_vars))
```

```{r}
# 📊 Coalesce rows: keep *non-NA values* where possible
df_merged <- df %>%
  group_by(sona) %>%
  summarise(across(everything(), ~ reduce(.x, coalesce)), .groups = "drop")

debug_df <- df %>%
  filter(sona %in% duplicated_ids_list) %>%
  arrange(sona)
View(debug_df)

# 🔍 Identify numeric columns from df_merged, EXCLUDING `sona` if it was coerced
numeric_cols <- df_merged %>%
  select(where(is.numeric)) %>%
  names() %>%
  setdiff("sona")

# 📋 Preview
head(numeric_cols)

# 🔍 Identify numeric columns containing 99s
columns_with_99 <- df %>%
  select(where(is.numeric)) %>%
  select(where(~ any(. == 99, na.rm = TRUE))) %>%
  names()

# 📊 Count how many 99s are in each column
count_99s <- sapply(df[columns_with_99], function(x) sum(x == 99, na.rm = TRUE))
cat("🔢 Number of 99s to convert to NA:\n")
print(count_99s)

# 🔄 Replace 99s with NA in those columns
df[columns_with_99] <- lapply(df[columns_with_99], function(x) replace(x, x == 99, NA))

# 📍 Identify duplicated sona IDs (before merging)
duplicated_ids_list <- df %>%
  count(sona) %>%
  filter(n > 1) %>%
  pull(sona)

# 📄 Create a tibble of all rows with those IDs
duplicated_ids <- df %>%
  filter(sona %in% duplicated_ids_list) %>%
  arrange(sona)

# 💾 Export to CSV for manual inspection
output_path <- here::here("data", "drm_r", "outputs", "duplicated_ids.csv")
write_csv(duplicated_ids, output_path)

# 👁️ Done! View it in RStudio
View(duplicated_ids)

# 🧾 Check number of unique vs original SONA rows
cat("Original rows:", nrow(df), "\n")
cat("After merge:", nrow(df_merged), "\n")

# 🪟 View a few cases to verify
df_merged %>% filter(sona %in% c("78559", "72349")) %>% View()

# ✅ Confirm remaining rows
cat("Remaining rows after coalescing duplicate sona entries:", nrow(df), "\n")
```

## 🚫 Drop Participants Without Episode-Level Data

```{r}

# 🧼 Drop rows where `sona` matches any in `drop_ids`
df <- df %>% 
  filter(!(sona %in% drop_ids))

# ✅ Confirm how many rows remain
cat("Remaining participants after exclusion:", nrow(df), "\n")
```

## 🚫 Drop Columns Without Useful Data
```{r}
# 🧹 Identify columns to drop by pattern (prefix or exact match)
cols_to_drop <- grep(
  "^start_date|^end_date|^status|^progress|^ip_address|^q_recaptcha_score|^finished|^distribution_channel|^user_language|^no_consent_exit|^recorded_date|^response_id",
  names(df_merged),
  value = TRUE
)

# 👀 Preview the columns that will be removed
cat("Columns to be dropped:\n")
print(cols_to_drop)

# 🧽 Drop the columns from df_merged and assign to df
df <- df_merged %>%
  select(-all_of(cols_to_drop))

cat("Final number of rows:", nrow(df), "\n")
head(df)

```

##✅ 🔍 Flag Missing SONA IDs

```{r}
df <- df %>%
  mutate(sona_status = case_when(
    is.na(sona) ~ "missing",
    TRUE ~ "present"
  ))

# 🔢 Count how many are missing
table(df$sona_status)
```

## 📊 Export Summary Statistics

```{r}
# 📋 Create a summary table
summary_df <- as.data.frame(summary(df))

# 💾 Define output file path
output_file <- here("data", "drm_r", "outputs", paste0("summary_", Sys.Date(), ".csv"))

# 📤 Save to outputs folder
write_csv(summary_df, output_file)
```

## Manual Instructions to Commit to GitHub (i.e., not auto)

```{text}
# 🚀 Manually run this chunk when you're ready to commit

# Set your commit message manually here
message <- "Quick update via Quarto chunk"

# Commit and push to GitHub
system("git add .")
system(paste('git commit -m', shQuote(message)))
system("git push")

---
### 🧠 Why `eval=FALSE`?

# - So the commit isn’t triggered **automatically** every time you render.
# - You’ll run this chunk manually (e.g., click the green ▶️ in the corner), **when** you want to push to GitHub.

```
--------------------

## 🚫 .gitignore Reference

```{text}
# RStudio project files
.Rproj.user/
.Rhistory
.RData
.DS_Store

# Quarto/knitr cache and output
*_cache/
*_files/

# Rendered output files
outputs/
*.html
*.pdf
*.docx

# Raw data
data/*.csv
data/*.xlsx
```

## 🚧 Identify Numeric Variables

```{r}
# 🔍 Re-identify numeric columns from final df
numeric_cols <- df %>%
  select(where(is.numeric)) %>%
  names()

# 🧾 Print preview of available numeric columns
cat("Preview of numeric columns in final df:\n")
print(head(numeric_cols))

# 👀 Check first few rows of numeric data
df %>%
  select(all_of(head(numeric_cols, 5))) %>%
  slice_head(n = 10)


# 🔁 Try to convert character columns to numeric where possible
df <- df %>%
  mutate(across(where(is.character), ~ suppressWarnings(as.numeric(.x)), .names = "num_{.col}"))

# 🔍 Now select the newly created numeric columns
numeric_cols <- df %>%
  select(starts_with("num_")) %>%
  names()

# 🧾 Confirm that it worked
head(numeric_cols)
```

## 🚨 Flag Potential Outliers (±3 SD)

```{r}
# 🔍 Re-identify numeric columns from df
numeric_cols <- df %>%
  select(where(is.numeric)) %>%
  names()

# 🔢 Show how many numeric columns
cat("Number of numeric columns being checked for outliers:", length(numeric_cols), "\n")

# ⚠️ Flag outliers using ±3 SD rule
outlier_df <- df %>%
  select(all_of(numeric_cols)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  mutate(
    mean_val = mean(value, na.rm = TRUE),
    sd_val   = sd(value, na.rm = TRUE),
    is_outlier = abs(value - mean_val) > 3 * sd_val
  ) %>%
  filter(is_outlier)

# 🧾 Show results
cat("Number of outliers flagged:", nrow(outlier_df), "\n")
head(outlier_df)

```

# NOTE: CONEVERT BELOW TO r INSTEAD OF TEXT

## Audio Missingness Patterns

```{r}
missing_summary <- df_merged %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_n") %>%
  arrange(desc(missing_n))
```

## Tag Columns That Represent Non-Selections

```{text}

# Recode NAs to 0 if NA means "not selected"
df_episode <- df_episode %>%
  mutate(across(matches("^c[0-9]+option[0-9]+$"), ~ replace_na(., 0)))  # adjust regex as needed

```

## Set a Threshold to Flag “Too Much Missing”

```{text}

df_episode %>%
  group_by(sona) %>%
  summarise(missing_rate = mean(is.na(emotion_regulation_score))) %>%
  filter(missing_rate > 0.5)
```

## Don't Impute - Summarize With NA-Resilient Functions

```{text}
df %>%
  summarise(across(where(is.numeric), list(mean = ~mean(., na.rm = TRUE),
                                           sd = ~sd(., na.rm = TRUE),
                                           n = ~sum(!is.na(.)))))
```


## Flag Cases with Partial Completion

```{text}
df <- df %>%
  mutate(partially_complete = rowMeans(is.na(across(starts_with("q")))) > 0.3)
```

## Document Assumptions About Missingness

```{text}
In your analytic memo or script comments, briefly document:

- When missing = skipped vs. not applicable
- That you use NA-resilient summaries
- That no listwise deletion or imputation was used (unless added later)
```

## Create missingness_df for Review

```{text}
missingness_df <- df_merged %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
  arrange(desc(n_missing))
```

